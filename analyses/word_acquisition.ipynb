{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import List\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import string\n",
    "import spacy\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_surprisals(words:List[str], surprisals_df):\n",
    "    num_words = len(words)\n",
    "    cols = min(num_words, 3)\n",
    "    rows = math.ceil(num_words / cols)\n",
    "\n",
    "    plt.style.use('ggplot')\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(cols*3, rows*3))\n",
    "    axs = np.atleast_2d(axs)\n",
    "\n",
    "    for i, word in enumerate(words):   \n",
    "        word_data = surprisals_df[surprisals_df['Token'] == word].iloc[1:]  # mention this\n",
    "        if word_data.empty:\n",
    "            print(f'No data found for the word \"{word}\"')\n",
    "            continue\n",
    "\n",
    "        ax = axs[i//cols, i%cols]\n",
    "        ax.plot(word_data['Steps'], word_data['MeanSurprisal'], marker='o')\n",
    "        ax.set_title(f'\"{word}\"')\n",
    "        ax.set_xlabel('Steps (log10)')\n",
    "        ax.set_ylabel('Mean surprisal')\n",
    "        ax.set_xscale('log')\n",
    "        ax.invert_yaxis()\n",
    "\n",
    "    # Remove empty subplots\n",
    "    for j in range(i+1, rows*cols):\n",
    "        fig.delaxes(axs.flatten()[j])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikitext_surprisals = 'sample_data/wikitext/bert_surprisals_large.txt'\n",
    "chang_bergen_surprisals = 'r_code/tacl_data/lm_data/bert_surprisals.txt'\n",
    "surprisals = pd.read_csv(wikitext_surprisals, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surprisals = (surprisals\n",
    "    .sort_values(['Token', 'Steps'])\n",
    "    .groupby('Token')\n",
    "    .apply(lambda x: x.assign(MeanSurprisalDiff = x['MeanSurprisal'].diff().fillna(0), \n",
    "                              StdevSurprisalDiff = x['StdevSurprisal'].diff().fillna(0)))\n",
    "    .reset_index(drop=True))\n",
    "\n",
    "surprisals.insert(0, 'Token', surprisals.pop('Token'))\n",
    "surprisals = surprisals[surprisals['Token'].apply(lambda t: t.isascii() and not t.isdigit())]\n",
    "surprisals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surprisals['Token'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random_1 = random.choice(surprisals['Token'].unique().tolist())\n",
    "random_2 = random.choice(surprisals['Token'].unique().tolist())\n",
    "plot_surprisals(['walk', random_1, random_2], surprisals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most vs least frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent = surprisals[surprisals['NumExamples'] == 512]\n",
    "infrequent = surprisals[surprisals['NumExamples'] == 1]\n",
    "\n",
    "print(f'Percentage of frequent words in the dataset (occuring at least 512 times): {len(frequent)/len(surprisals)*100:.2f}%')\n",
    "print(f'Percentage of infrequent words in the dataset (occuring only once): {len(infrequent)/len(surprisals)*100:.2f}%')\n",
    "\n",
    "plot_surprisals(\n",
    "    frequent['Token'].drop_duplicates().sample(1).tolist() + infrequent['Token'].drop_duplicates().sample(1).tolist(), \n",
    "    surprisals\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each step, average surprisal across all words\n",
    "\n",
    "avg_surprisals = surprisals.groupby('Steps')['MeanSurprisal'].mean().reset_index()\n",
    "avg_surprisals.plot(x='Steps', y='MeanSurprisal', logx=True)\\\n",
    "    .set_ylim(avg_surprisals['MeanSurprisal'].iloc[1:].max(), avg_surprisals['MeanSurprisal'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each step, average surprisal across all words with at least 512 examples (frequent words)\n",
    "avg_freq_surprisals = frequent.groupby('Steps')['MeanSurprisal'].mean().reset_index().assign(Diffs=lambda x: x['MeanSurprisal'].diff().fillna(0))\n",
    "\n",
    "# for each step, average surprisal across all words with only 1 example (infrequent words)\n",
    "avg_infreq_surprisals = infrequent.groupby('Steps')['MeanSurprisal'].mean().reset_index().assign(Diffs=lambda x: x['MeanSurprisal'].diff().fillna(0))\n",
    "\n",
    "plt.figure()\n",
    "plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "\n",
    "plt.plot(avg_freq_surprisals['Steps'] + 10000, avg_freq_surprisals['MeanSurprisal'], marker='o', label='Frequent Words')\n",
    "plt.plot(avg_infreq_surprisals['Steps'] + 10000, avg_infreq_surprisals['MeanSurprisal'], marker='o', label='Infrequent Words')\n",
    "\n",
    "plt.ylim(max(avg_freq_surprisals['MeanSurprisal'].max(), avg_infreq_surprisals['MeanSurprisal'].max()), 0)\n",
    "plt.xlabel('Steps (log 10)')\n",
    "plt.ylabel('Mean Surprisal')\n",
    "plt.legend()\n",
    "\n",
    "print('Frequent words (>= 512 examples):')\n",
    "print(f\"Min surprisal: {avg_freq_surprisals['MeanSurprisal'].min():.2f}\")\n",
    "print(f\"Max surprisal (excluding the first step): {avg_freq_surprisals['MeanSurprisal'].iloc[1:].max():.2f}\")\n",
    "print(f\"Average variability (excluding the first step): {avg_freq_surprisals['Diffs'].iloc[2:].mean():.2f}\\n\")\n",
    "\n",
    "print('Inrequent words (= 1 example):')\n",
    "print(f\"Min surprisal: {avg_infreq_surprisals['MeanSurprisal'].min():.2f}\")\n",
    "print(f\"Max surprisal (excluding the first step): {avg_infreq_surprisals['MeanSurprisal'].iloc[1:].max():.2f}\")\n",
    "print(f\"Average variability (excluding the first step): {avg_infreq_surprisals['Diffs'].iloc[2:].mean():.2f}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_surprisals(bert_surprisals['Token'].drop_duplicates().tolist(), bert_surprisals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words with different POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_tags(doc_path):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    nlp.max_length = 2000000\n",
    "    pos_dict = {}\n",
    "    with open(doc_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "        doc = nlp(text)\n",
    "        for token in doc:\n",
    "            if token.text in pos_dict and not token.pos_ in pos_dict[token.text]:\n",
    "                pos_dict[token.text].append(token.pos_)\n",
    "            else:\n",
    "                pos_dict[token.text] = [token.pos_]\n",
    "        \n",
    "    return pd.DataFrame(list(pos_dict.items()), columns=['Token', 'POS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_avg(dfs: List[pd.DataFrame]):\n",
    "    plt.figure()\n",
    "    max_y = 0\n",
    "    min_y = float('inf')\n",
    "    for df in dfs:\n",
    "        avg = (df.groupby('Steps')\n",
    "                 .agg({'MeanSurprisal': 'mean', 'POS': 'first'})\n",
    "                 .reset_index()\n",
    "                 .assign(Diffs=lambda x: x['MeanSurprisal'].diff().fillna(0)))\n",
    "\n",
    "        plt.plot(avg['Steps'] + 10000, avg['MeanSurprisal'], \n",
    "                 label=f\"{avg['POS'].values[0][0]} (var: {avg['Diffs'].iloc[2:].mean():.2f})\")\n",
    "        max_y = avg['MeanSurprisal'].max() if avg['MeanSurprisal'].max() > max_y else max_y\n",
    "        min_y = avg['MeanSurprisal'].min() if avg['MeanSurprisal'].min() < min_y else min_y\n",
    "\n",
    "    plt.ylim(max_y, min_y - 1)\n",
    "    plt.xlabel('Steps (log 10)')\n",
    "    plt.ylabel('Mean Surprisal')\n",
    "    plt.xscale('log')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"sample_data/wikitext/wikitext103_test.txt\"\n",
    "pos_tags = get_pos_tags(document)\n",
    "pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(surprisals, pos_tags, on='Token', how='inner')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pos_tags = set([pos for pos_list in merged_df['POS'] if isinstance(pos_list, list) for pos in pos_list])\n",
    "all_pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nouns = merged_df[merged_df['POS'].apply(lambda pos_list: 'NOUN' in pos_list)]['Token'].nunique()\n",
    "num_verbs = merged_df[merged_df['POS'].apply(lambda pos_list: 'VERB' in pos_list)]['Token'].nunique()\n",
    "num_adjs = merged_df[merged_df['POS'].apply(lambda pos_list: 'ADJ' in pos_list)]['Token'].nunique()\n",
    "num_advs = merged_df[merged_df['POS'].apply(lambda pos_list: 'ADV' in pos_list)]['Token'].nunique()\n",
    "\n",
    "print(f\"Total number of nouns: {num_nouns}\")\n",
    "print(f\"Total number of verbs: {num_verbs}\")\n",
    "print(f\"Total number of adjectives: {num_adjs}\")\n",
    "print(f\"Total number of adverbs: {num_advs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclusive_noun = merged_df[merged_df['POS'].apply(lambda pos_list: 'NOUN' in pos_list and len(pos_list) == 1)]\n",
    "exclusive_verb = merged_df[merged_df['POS'].apply(lambda pos_list: 'VERB' in pos_list and len(pos_list) == 1)]\n",
    "adj = merged_df[merged_df['POS'].apply(lambda pos_list: 'ADJ' in pos_list and len(pos_list) == 1)]\n",
    "adv = merged_df[merged_df['POS'].apply(lambda pos_list: 'ADV' in pos_list and len(pos_list) == 1)]\n",
    "\n",
    "noun_sample = exclusive_noun['Token'].drop_duplicates().sample(3).tolist()\n",
    "verb_sample = exclusive_verb['Token'].drop_duplicates().sample(3).tolist()\n",
    "adj_sample = adj['Token'].drop_duplicates().sample(3).tolist()\n",
    "adv_sample = adv['Token'].drop_duplicates().sample(3).tolist()\n",
    "\n",
    "plot_surprisals(\n",
    "    noun_sample + verb_sample + adj_sample + adv_sample, \n",
    "    merged_df\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_avg([exclusive_verb, exclusive_noun, adv, adj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_avg([exclusive_verb, exclusive_verb[exclusive_verb['Token'] == 'walk']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 5 largest and smallest absolute diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_abs_diffs = merged_df.loc[merged_df['MeanSurprisalDiff'].abs().nlargest(5).index]\n",
    "largest_abs_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smallest_abs_diffs = merged_df[merged_df['Steps'] != 0].sort_values(by='MeanSurprisalDiff', key=abs).head(5)\n",
    "smallest_abs_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_diffs = merged_df.groupby('Steps').apply(lambda df: df.nlargest(5, 'MeanSurprisalDiff')).reset_index(drop=True)\n",
    "largest_diffs[largest_diffs['Steps'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smallest_diffs = merged_df.groupby('Steps').apply(lambda df: df.nsmallest(5, 'MeanSurprisalDiff')).reset_index(drop=True)\n",
    "smallest_diffs[smallest_diffs['Steps'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_abs_diffs = merged_df.groupby('Steps').apply(lambda df: df.loc[df['MeanSurprisalDiff'].abs().nlargest(1).index])\n",
    "largest_abs_diffs[largest_abs_diffs['Steps'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smallest_abs_diffs = merged_df.groupby('Steps').apply(lambda df: df.loc[df['MeanSurprisalDiff'].abs().nsmallest(1).index])\n",
    "smallest_abs_diffs[smallest_abs_diffs['Steps'] != 0]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
